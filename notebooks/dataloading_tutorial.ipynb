{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "07ee97bc-13cb-42c4-8881-d2b33cae1815",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/envs/main/lib/python3.10/site-packages/tqdm/auto.py:22: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "from rich import print\n",
    "import os\n",
    "import pathlib\n",
    "import random\n",
    "import sys\n",
    "from asyncio.log import logger\n",
    "from collections import defaultdict\n",
    "from dataclasses import dataclass\n",
    "from math import floor\n",
    "from typing import Any, Dict, List, Optional, Tuple, Union\n",
    "\n",
    "from torchtyping import TensorType\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import pyarrow as pa\n",
    "import pyarrow.dataset as ds\n",
    "import pyarrow.parquet as pq\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import tqdm\n",
    "from hydra_zen import builds, instantiate\n",
    "from PIL import Image\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "from torchvision.transforms import Compose, RandomCrop, Resize, ToTensor\n",
    "from traitlets import Int\n",
    "from capit.core.data.config import ImageShape, ModalityConfig\n",
    "from capit.core.utils.storage import load_json, save_json\n",
    "\n",
    "from capit.decorators import configurable\n",
    "from capit.utils import get_logger\n",
    "from torch.utils.data.dataloader import default_collate\n",
    "\n",
    "logger = get_logger(__name__)\n",
    "\n",
    "os.environ[\"HYDRA_FULL_ERROR\"] = \"1\"\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a74225fd-95e7-4716-8589-0f419a41ebdd",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from capit.core.data.datasets import get_image_transforms_instait, \\\n",
    "        InstagramImageTextMultiModalDatasePyArrow, ChallengeSamplesSourceTypes, \\\n",
    "        SplitType \n",
    "\n",
    "root_filepath = pathlib.Path(\"/data/\")\n",
    "dataset_config = InstagramImageTextMultiModalDatasePyArrow.build_config(\n",
    "    populate_full_signature=True\n",
    ")\n",
    "dataset_config_instance = dataset_config(dataset_dir=root_filepath)\n",
    "train_dataset = InstagramImageTextMultiModalDatasePyArrow(\n",
    "    dataset_dir=root_filepath,\n",
    "    top_k_percent=25,\n",
    "    image_transforms=get_image_transforms_instait(),\n",
    "    max_num_collection_images_per_episode=0,\n",
    "    max_num_query_images_per_episode=25,\n",
    "    challenge_image_source=ChallengeSamplesSourceTypes.WITHIN_USER,\n",
    "    num_episodes=1000,\n",
    "    set_name=SplitType.TRAIN,\n",
    ")\n",
    "\n",
    "val_dataset = InstagramImageTextMultiModalDatasePyArrow(\n",
    "    dataset_dir=root_filepath,\n",
    "    top_k_percent=25,\n",
    "    image_transforms=get_image_transforms_instait(),\n",
    "    max_num_collection_images_per_episode=0,\n",
    "    max_num_query_images_per_episode=25,\n",
    "    challenge_image_source=ChallengeSamplesSourceTypes.WITHIN_USER,\n",
    "    num_episodes=1000,\n",
    "    set_name=SplitType.VAL,\n",
    ")\n",
    "\n",
    "test_dataset = InstagramImageTextMultiModalDatasePyArrow(\n",
    "    dataset_dir=root_filepath,\n",
    "    top_k_percent=25,\n",
    "    image_transforms=get_image_transforms_instait(),\n",
    "    max_num_collection_images_per_episode=0,\n",
    "    max_num_query_images_per_episode=25,\n",
    "    challenge_image_source=ChallengeSamplesSourceTypes.WITHIN_USER,\n",
    "    num_episodes=1000,\n",
    "    set_name=SplitType.TEST,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "8aa68700-99ed-4ef2-8f1b-efdcdd2fab02",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 24510/24510 [00:01<00:00, 12442.64it/s]\n",
      "100%|██████████| 3063/3063 [00:01<00:00, 2757.98it/s]\n",
      "100%|██████████| 3065/3065 [00:01<00:00, 2795.60it/s]\n"
     ]
    }
   ],
   "source": [
    "import tqdm\n",
    "train_usernames = train_dataset.set_usernames\n",
    "val_usernames = val_dataset.set_usernames\n",
    "test_usernames = test_dataset.set_usernames\n",
    "with tqdm.tqdm(total=len(train_usernames)) as pbar:\n",
    "    for username in train_usernames:\n",
    "        assert username not in val_usernames\n",
    "        assert username not in test_usernames\n",
    "        pbar.update(1)\n",
    "\n",
    "with tqdm.tqdm(total=len(val_usernames)) as pbar:\n",
    "    for username in val_usernames:\n",
    "        assert username not in train_usernames\n",
    "        assert username not in test_usernames\n",
    "        pbar.update(1)\n",
    "\n",
    "with tqdm.tqdm(total=len(test_usernames)) as pbar:\n",
    "    for username in test_usernames:\n",
    "        assert username not in train_usernames\n",
    "        assert username not in val_usernames\n",
    "        pbar.update(1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "84e244bc-3d45-43c8-84f2-658bd7e1b390",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  },
  "vscode": {
   "interpreter": {
    "hash": "8be86470e38501aa34785446b144512d347203ba2fe09ff4115a3f561b2ac78b"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
