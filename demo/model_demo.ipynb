{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "from typing import List\n",
    "import gradio as gr\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "from capit.core.data.datasets import *\n",
    "from capit.core.data.datasets_old import *\n",
    "from torchvision.transforms import Compose, RandomCrop, Resize, ToTensor\n",
    "\n",
    "\n",
    "def get_image_transforms_instait():\n",
    "    return Compose([Resize((224, 224)), ToTensor(), ToThreeChannels()])\n",
    "\n",
    "\n",
    "dataset_dir = \"/data_fast/\"\n",
    "dataset = InstagramImageTextMultiModalDatasePyArrow(\n",
    "    dataset_dir=dataset_dir,\n",
    "    set_name=SplitType.TRAIN,\n",
    "    top_k_percent=100,\n",
    "    reset_cache=False,\n",
    "    num_episodes=1000,\n",
    "    max_num_collection_images_per_episode=100,\n",
    "    max_num_query_images_per_episode=100,\n",
    "    challenge_image_source=ChallengeSamplesSourceTypes.WITHIN_USER,\n",
    "    dummy_batch_mode=False,\n",
    "    model_name_or_path=\"openai/clip-vit-base-patch32\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">target_image: <span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">torch.Size</span><span style=\"font-weight: bold\">([</span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">3</span>, <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">224</span>, <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">224</span><span style=\"font-weight: bold\">])</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "target_image: \u001b[1;35mtorch.Size\u001b[0m\u001b[1m(\u001b[0m\u001b[1m[\u001b[0m\u001b[1;36m3\u001b[0m, \u001b[1;36m224\u001b[0m, \u001b[1;36m224\u001b[0m\u001b[1m]\u001b[0m\u001b[1m)\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">challenge_images: <span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">torch.Size</span><span style=\"font-weight: bold\">([</span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">100</span>, <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">3</span>, <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">224</span>, <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">224</span><span style=\"font-weight: bold\">])</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "challenge_images: \u001b[1;35mtorch.Size\u001b[0m\u001b[1m(\u001b[0m\u001b[1m[\u001b[0m\u001b[1;36m100\u001b[0m, \u001b[1;36m3\u001b[0m, \u001b[1;36m224\u001b[0m, \u001b[1;36m224\u001b[0m\u001b[1m]\u001b[0m\u001b[1m)\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">target_text: <span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">torch.Size</span><span style=\"font-weight: bold\">([</span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">1</span>, <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">77</span><span style=\"font-weight: bold\">])</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "target_text: \u001b[1;35mtorch.Size\u001b[0m\u001b[1m(\u001b[0m\u001b[1m[\u001b[0m\u001b[1;36m1\u001b[0m, \u001b[1;36m77\u001b[0m\u001b[1m]\u001b[0m\u001b[1m)\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">target_text_str: <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">300</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "target_text_str: \u001b[1;36m300\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">challenge_paths: <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">100</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "challenge_paths: \u001b[1;36m100\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">collection_images: <span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">torch.Size</span><span style=\"font-weight: bold\">([</span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">100</span>, <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">3</span>, <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">224</span>, <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">224</span><span style=\"font-weight: bold\">])</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "collection_images: \u001b[1;35mtorch.Size\u001b[0m\u001b[1m(\u001b[0m\u001b[1m[\u001b[0m\u001b[1;36m100\u001b[0m, \u001b[1;36m3\u001b[0m, \u001b[1;36m224\u001b[0m, \u001b[1;36m224\u001b[0m\u001b[1m]\u001b[0m\u001b[1m)\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">collection_paths: <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">100</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "collection_paths: \u001b[1;36m100\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "for key, value in dataset[0].__dict__.items():\n",
    "    print(f\"{key}: {value.shape if hasattr(value, 'shape') else len(value)}\")\n",
    "\n",
    "\n",
    "def rank(prompt, sample_idx):\n",
    "    # randomize order of images\n",
    "    sample = dataset[sample_idx]\n",
    "    # collection_image_data = [item['image'] for item in sample.collection_paths] # sample.collection_images\n",
    "    # challenge_image_data = [item['image'] for item in sample.challenge_paths] # sample.challenge_images\n",
    "\n",
    "    images = [item[\"image\"] for item in sample.challenge_paths]\n",
    "    return np.random.permutation(images)\n",
    "\n",
    "\n",
    "class RandomModel:\n",
    "    def rank(self, prompt, sample_idx):\n",
    "        return rank(prompt, sample_idx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Token is valid.\n",
      "Your token has been saved in your configured git credential helpers (store).\n",
      "Your token has been saved to /home/evolvingfungus/.cache/huggingface/token\n",
      "Login successful\n"
     ]
    }
   ],
   "source": [
    "from typing import Union\n",
    "from huggingface_hub import login\n",
    "\n",
    "login(token=\"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\", add_to_git_credential=True)\n",
    "\n",
    "import torch\n",
    "from capit.core.models import *\n",
    "import torchvision.transforms as transforms\n",
    "from PIL import Image\n",
    "from capit.core.models import (\n",
    "    CLIPImageTextModel,\n",
    "    CLIPWithPostProcessingImageTextModel,\n",
    "    CAPCLIPImageTextModel,\n",
    ")\n",
    "from capit.core.data.datasets import ImageTextRetrievalInput\n",
    "\n",
    "accelerator = Accelerator(mixed_precision=\"bf16\")\n",
    "\n",
    "\n",
    "class Ranker(nn.Module):\n",
    "    def __init__(\n",
    "        self,\n",
    "        model_type: Union[\n",
    "            CLIPImageTextModel,\n",
    "            CLIPWithPostProcessingImageTextModel,\n",
    "            CAPCLIPImageTextModel,\n",
    "        ],\n",
    "        model_name_or_path: str,\n",
    "        repo_path: str,\n",
    "        model_name: str,\n",
    "        batch: ImageTextRetrievalInput,\n",
    "        cache_path: str = \".cache/\",\n",
    "        pretrained: bool = True,\n",
    "        backbone_fine_tunable: bool = True,\n",
    "    ):\n",
    "        super().__init__()\n",
    "        if model_type != CAPCLIPImageTextModel:\n",
    "            self.model = model_type(\n",
    "                pretrained=pretrained, model_name_or_path=model_name_or_path\n",
    "            )\n",
    "        else:\n",
    "            self.model = model_type(\n",
    "                pretrained=pretrained,\n",
    "                model_name_or_path=model_name_or_path,\n",
    "                backbone_fine_tunable=backbone_fine_tunable,\n",
    "            )\n",
    "        self.model.build(batch=batch)\n",
    "        self.accelerator = Accelerator(mixed_precision=\"bf16\")\n",
    "        self.model = self.accelerator.prepare(self.model)\n",
    "        self.model_name_or_path = model_name_or_path\n",
    "        self.pretrained = pretrained\n",
    "        self.load_from_repo(\n",
    "            hf_repo_path=repo_path,\n",
    "            model_name=model_name,\n",
    "            hf_cache_dir=cache_path,\n",
    "        )\n",
    "        # hf_repo_path: str, model_name: str, hf_cache_dir: str\n",
    "\n",
    "    def rank(self, prompt_text, sample_idx):\n",
    "        with torch.no_grad():\n",
    "            sample = dataset[sample_idx]\n",
    "            collection_image_data = sample.collection_images.to(\n",
    "                accelerator.device\n",
    "            )\n",
    "            challenge_image_data = sample.challenge_images.to(\n",
    "                accelerator.device\n",
    "            )\n",
    "            prompt_text_ids = dataset.processor(\n",
    "                text=prompt_text,\n",
    "                padding=True,\n",
    "                truncation=True,\n",
    "                return_tensors=\"pt\",\n",
    "            )[\"input_ids\"].to(accelerator.device)\n",
    "\n",
    "            # print(prompt_text_ids.shape, challenge_image_data.shape, collection_image_data.shape)\n",
    "\n",
    "            similarities = self.model.predict_individual(\n",
    "                challenge_image_data, prompt_text_ids, collection_image_data\n",
    "            )\n",
    "            rank_similarities_args = torch.argsort(\n",
    "                similarities, descending=True\n",
    "            )[0]\n",
    "            return [\n",
    "                sample.challenge_paths[i][\"image\"]\n",
    "                for i in rank_similarities_args\n",
    "            ]\n",
    "\n",
    "    def load_from_repo(\n",
    "        self, hf_repo_path: str, model_name: str, hf_cache_dir: str\n",
    "    ):\n",
    "        download_output = download_model_with_name(\n",
    "            hf_repo_path,\n",
    "            hf_cache_dir,\n",
    "            model_name,\n",
    "            download_only_if_finished=False,\n",
    "        )\n",
    "\n",
    "        checkpoint_path = download_output[\"root_filepath\"]\n",
    "        checkpoint_path = (\n",
    "            checkpoint_path\n",
    "            if isinstance(checkpoint_path, pathlib.Path)\n",
    "            else pathlib.Path(checkpoint_path)\n",
    "        )\n",
    "\n",
    "        logger.info(f\"Loading checkpoint from {checkpoint_path}\")\n",
    "\n",
    "        self.accelerator.load_state(checkpoint_path)\n",
    "\n",
    "        return checkpoint_path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/evolvingfungus/miniconda/envs/minimal-ml-template/lib/python3.10/site-packages/transformers/models/clip/processing_clip.py:142: FutureWarning: `feature_extractor` is deprecated and will be removed in v5. Use `image_processor` instead.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "75bcea3930044ba5a2acf4da72f151de",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading (…)lve/main/config.yaml:   0%|          | 0.00/3.46k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "490f57fc2444407c8ccb900de4616656",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading trainer_state.pt:   0%|          | 0.00/76.0k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3f07a73543af44e8a67d936d7d70de23",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading optimizer.bin:   0%|          | 0.00/2.23k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "260f1a90953a4d8a9c11dbb5e53fbf0e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading pytorch_model.bin:   0%|          | 0.00/605M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6f01a61fea764e468952a74f1c831db5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading random_states_0.pkl:   0%|          | 0.00/14.6k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #800000; text-decoration-color: #800000\">╭─────────────────────────────────────── </span><span style=\"color: #800000; text-decoration-color: #800000; font-weight: bold\">Traceback </span><span style=\"color: #bf7f7f; text-decoration-color: #bf7f7f; font-weight: bold\">(most recent call last)</span><span style=\"color: #800000; text-decoration-color: #800000\"> ───────────────────────────────────────╮</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span> in <span style=\"color: #00ff00; text-decoration-color: #00ff00\">&lt;module&gt;</span>                                                                                                     <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>                                                                                                                 <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 7 </span>dummy_batch = dataset[<span style=\"color: #0000ff; text-decoration-color: #0000ff\">0</span>].<span style=\"color: #ff0000; text-decoration-color: #ff0000\">__class__</span>(**dummy_dict_batch)                                                     <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span> <span style=\"color: #800000; text-decoration-color: #800000\">❱ </span> 8 baseline = Ranker(                                                                                         <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 9 │   </span>model_type=CLIPImageTextModel,                                                                         <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>                                                                                                                 <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span> in <span style=\"color: #00ff00; text-decoration-color: #00ff00\">__init__</span>                                                                                                     <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>                                                                                                                 <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">50 │   │   </span><span style=\"color: #00ffff; text-decoration-color: #00ffff\">self</span>.pretrained = pretrained                                                                       <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span> <span style=\"color: #800000; text-decoration-color: #800000\">❱ </span>51 <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   </span><span style=\"color: #00ffff; text-decoration-color: #00ffff\">self</span>.load_from_repo(                                                                               <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">52 │   │   │   </span>hf_repo_path=repo_path, model_name=model_name, hf_cache_dir=cache_path                         <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>                                                                                                                 <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span> in <span style=\"color: #00ff00; text-decoration-color: #00ff00\">load_from_repo</span>                                                                                               <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>                                                                                                                 <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">88 │   │   </span>                                                                                                   <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span> <span style=\"color: #800000; text-decoration-color: #800000\">❱ </span>89 <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   </span><span style=\"color: #00ffff; text-decoration-color: #00ffff\">self</span>.accelerator.load_state(checkpoint_path)                                                       <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">90 </span>                                                                                                           <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>                                                                                                                 <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span> <span style=\"color: #bfbf7f; text-decoration-color: #bfbf7f\">/home/evolvingfungus/miniconda/envs/minimal-ml-template/lib/python3.10/site-packages/accelerate/</span><span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\">accelerator.py</span>: <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span> <span style=\"color: #0000ff; text-decoration-color: #0000ff\">2145</span> in <span style=\"color: #00ff00; text-decoration-color: #00ff00\">load_state</span>                                                                                              <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>                                                                                                                 <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">2144 │   │   </span>                                                                                                 <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span> <span style=\"color: #800000; text-decoration-color: #800000\">❱ </span>2145 <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   </span>load_accelerator_state(                                                                          <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">2146 │   │   │   </span>input_dir, models, optimizers, schedulers, <span style=\"color: #00ffff; text-decoration-color: #00ffff\">self</span>.state.process_index,                         <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>        <span style=\"color: #00ffff; text-decoration-color: #00ffff\">self</span>.scaler, **load_model_func_kwargs                                                                    <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>                                                                                                                 <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span> <span style=\"color: #bfbf7f; text-decoration-color: #bfbf7f\">/home/evolvingfungus/miniconda/envs/minimal-ml-template/lib/python3.10/site-packages/accelerate/</span><span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\">checkpointing.p</span> <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span> <span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\">y</span>:<span style=\"color: #0000ff; text-decoration-color: #0000ff\">158</span> in <span style=\"color: #00ff00; text-decoration-color: #00ff00\">load_accelerator_state</span>                                                                                 <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>                                                                                                                 <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">157 │   │   </span>input_scaler_file = os.path.join(input_dir, SCALER_NAME)                                          <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span> <span style=\"color: #800000; text-decoration-color: #800000\">❱ </span>158 <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   </span>scaler.load_state_dict(torch.load(input_scaler_file))                                             <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">159 │   │   </span>logger.info(<span style=\"color: #808000; text-decoration-color: #808000\">\"GradScaler state loaded successfully\"</span>)                                               <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>                                                                                                                 <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span> <span style=\"color: #bfbf7f; text-decoration-color: #bfbf7f\">/home/evolvingfungus/miniconda/envs/minimal-ml-template/lib/python3.10/site-packages/torch/</span><span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\">serialization.py</span>:<span style=\"color: #0000ff; text-decoration-color: #0000ff\">771</span> <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span> in <span style=\"color: #00ff00; text-decoration-color: #00ff00\">load</span>                                                                                                         <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>                                                                                                                 <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 770 │   </span>                                                                                                     <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span> <span style=\"color: #800000; text-decoration-color: #800000\">❱ </span> 771 <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   </span><span style=\"color: #0000ff; text-decoration-color: #0000ff\">with</span> _open_file_like(f, <span style=\"color: #808000; text-decoration-color: #808000\">'rb'</span>) <span style=\"color: #0000ff; text-decoration-color: #0000ff\">as</span> opened_file:                                                        <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 772 │   │   </span><span style=\"color: #0000ff; text-decoration-color: #0000ff\">if</span> _is_zipfile(opened_file):                                                                     <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>                                                                                                                 <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span> <span style=\"color: #bfbf7f; text-decoration-color: #bfbf7f\">/home/evolvingfungus/miniconda/envs/minimal-ml-template/lib/python3.10/site-packages/torch/</span><span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\">serialization.py</span>:<span style=\"color: #0000ff; text-decoration-color: #0000ff\">270</span> <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span> in <span style=\"color: #00ff00; text-decoration-color: #00ff00\">_open_file_like</span>                                                                                              <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>                                                                                                                 <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 269 │   </span><span style=\"color: #0000ff; text-decoration-color: #0000ff\">if</span> _is_path(name_or_buffer):                                                                         <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span> <span style=\"color: #800000; text-decoration-color: #800000\">❱ </span> 270 <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   </span><span style=\"color: #0000ff; text-decoration-color: #0000ff\">return</span> _open_file(name_or_buffer, mode)                                                          <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 271 │   </span><span style=\"color: #0000ff; text-decoration-color: #0000ff\">else</span>:                                                                                                <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>                                                                                                                 <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span> <span style=\"color: #bfbf7f; text-decoration-color: #bfbf7f\">/home/evolvingfungus/miniconda/envs/minimal-ml-template/lib/python3.10/site-packages/torch/</span><span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\">serialization.py</span>:<span style=\"color: #0000ff; text-decoration-color: #0000ff\">251</span> <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span> in <span style=\"color: #00ff00; text-decoration-color: #00ff00\">__init__</span>                                                                                                     <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>                                                                                                                 <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 250 │   </span><span style=\"color: #0000ff; text-decoration-color: #0000ff\">def</span> <span style=\"color: #00ff00; text-decoration-color: #00ff00\">__init__</span>(<span style=\"color: #00ffff; text-decoration-color: #00ffff\">self</span>, name, mode):                                                                      <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span> <span style=\"color: #800000; text-decoration-color: #800000\">❱ </span> 251 <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   </span><span style=\"color: #00ffff; text-decoration-color: #00ffff\">super</span>(_open_file, <span style=\"color: #00ffff; text-decoration-color: #00ffff\">self</span>).<span style=\"color: #00ff00; text-decoration-color: #00ff00\">__init__</span>(<span style=\"color: #00ffff; text-decoration-color: #00ffff\">open</span>(name, mode))                                               <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 252 </span>                                                                                                         <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">╰─────────────────────────────────────────────────────────────────────────────────────────────────────────────────╯</span>\n",
       "<span style=\"color: #ff0000; text-decoration-color: #ff0000; font-weight: bold\">FileNotFoundError: </span><span style=\"font-weight: bold\">[</span>Errno <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">2</span><span style=\"font-weight: bold\">]</span> No such file or directory: <span style=\"color: #008000; text-decoration-color: #008000\">'/data_fast/models/clip-base/checkpoints/ckpt_0/scaler.pt'</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[31m╭─\u001b[0m\u001b[31m──────────────────────────────────────\u001b[0m\u001b[31m \u001b[0m\u001b[1;31mTraceback \u001b[0m\u001b[1;2;31m(most recent call last)\u001b[0m\u001b[31m \u001b[0m\u001b[31m──────────────────────────────────────\u001b[0m\u001b[31m─╮\u001b[0m\n",
       "\u001b[31m│\u001b[0m in \u001b[92m<module>\u001b[0m                                                                                                     \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m                                                                                                                 \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m 7 \u001b[0mdummy_batch = dataset[\u001b[94m0\u001b[0m].\u001b[91m__class__\u001b[0m(**dummy_dict_batch)                                                     \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m \u001b[31m❱ \u001b[0m 8 baseline = Ranker(                                                                                         \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m 9 \u001b[0m\u001b[2m│   \u001b[0mmodel_type=CLIPImageTextModel,                                                                         \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m                                                                                                                 \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m in \u001b[92m__init__\u001b[0m                                                                                                     \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m                                                                                                                 \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m50 \u001b[0m\u001b[2m│   │   \u001b[0m\u001b[96mself\u001b[0m.pretrained = pretrained                                                                       \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m \u001b[31m❱ \u001b[0m51 \u001b[2m│   │   \u001b[0m\u001b[96mself\u001b[0m.load_from_repo(                                                                               \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m52 \u001b[0m\u001b[2m│   │   │   \u001b[0mhf_repo_path=repo_path, model_name=model_name, hf_cache_dir=cache_path                         \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m                                                                                                                 \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m in \u001b[92mload_from_repo\u001b[0m                                                                                               \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m                                                                                                                 \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m88 \u001b[0m\u001b[2m│   │   \u001b[0m                                                                                                   \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m \u001b[31m❱ \u001b[0m89 \u001b[2m│   │   \u001b[0m\u001b[96mself\u001b[0m.accelerator.load_state(checkpoint_path)                                                       \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m90 \u001b[0m                                                                                                           \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m                                                                                                                 \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m \u001b[2;33m/home/evolvingfungus/miniconda/envs/minimal-ml-template/lib/python3.10/site-packages/accelerate/\u001b[0m\u001b[1;33maccelerator.py\u001b[0m: \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m \u001b[94m2145\u001b[0m in \u001b[92mload_state\u001b[0m                                                                                              \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m                                                                                                                 \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m2144 \u001b[0m\u001b[2m│   │   \u001b[0m                                                                                                 \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m \u001b[31m❱ \u001b[0m2145 \u001b[2m│   │   \u001b[0mload_accelerator_state(                                                                          \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m2146 \u001b[0m\u001b[2m│   │   │   \u001b[0minput_dir, models, optimizers, schedulers, \u001b[96mself\u001b[0m.state.process_index,                         \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m        \u001b[96mself\u001b[0m.scaler, **load_model_func_kwargs                                                                    \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m                                                                                                                 \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m \u001b[2;33m/home/evolvingfungus/miniconda/envs/minimal-ml-template/lib/python3.10/site-packages/accelerate/\u001b[0m\u001b[1;33mcheckpointing.p\u001b[0m \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m \u001b[1;33my\u001b[0m:\u001b[94m158\u001b[0m in \u001b[92mload_accelerator_state\u001b[0m                                                                                 \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m                                                                                                                 \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m157 \u001b[0m\u001b[2m│   │   \u001b[0minput_scaler_file = os.path.join(input_dir, SCALER_NAME)                                          \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m \u001b[31m❱ \u001b[0m158 \u001b[2m│   │   \u001b[0mscaler.load_state_dict(torch.load(input_scaler_file))                                             \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m159 \u001b[0m\u001b[2m│   │   \u001b[0mlogger.info(\u001b[33m\"\u001b[0m\u001b[33mGradScaler state loaded successfully\u001b[0m\u001b[33m\"\u001b[0m)                                               \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m                                                                                                                 \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m \u001b[2;33m/home/evolvingfungus/miniconda/envs/minimal-ml-template/lib/python3.10/site-packages/torch/\u001b[0m\u001b[1;33mserialization.py\u001b[0m:\u001b[94m771\u001b[0m \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m in \u001b[92mload\u001b[0m                                                                                                         \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m                                                                                                                 \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m 770 \u001b[0m\u001b[2m│   \u001b[0m                                                                                                     \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m \u001b[31m❱ \u001b[0m 771 \u001b[2m│   \u001b[0m\u001b[94mwith\u001b[0m _open_file_like(f, \u001b[33m'\u001b[0m\u001b[33mrb\u001b[0m\u001b[33m'\u001b[0m) \u001b[94mas\u001b[0m opened_file:                                                        \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m 772 \u001b[0m\u001b[2m│   │   \u001b[0m\u001b[94mif\u001b[0m _is_zipfile(opened_file):                                                                     \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m                                                                                                                 \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m \u001b[2;33m/home/evolvingfungus/miniconda/envs/minimal-ml-template/lib/python3.10/site-packages/torch/\u001b[0m\u001b[1;33mserialization.py\u001b[0m:\u001b[94m270\u001b[0m \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m in \u001b[92m_open_file_like\u001b[0m                                                                                              \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m                                                                                                                 \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m 269 \u001b[0m\u001b[2m│   \u001b[0m\u001b[94mif\u001b[0m _is_path(name_or_buffer):                                                                         \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m \u001b[31m❱ \u001b[0m 270 \u001b[2m│   │   \u001b[0m\u001b[94mreturn\u001b[0m _open_file(name_or_buffer, mode)                                                          \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m 271 \u001b[0m\u001b[2m│   \u001b[0m\u001b[94melse\u001b[0m:                                                                                                \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m                                                                                                                 \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m \u001b[2;33m/home/evolvingfungus/miniconda/envs/minimal-ml-template/lib/python3.10/site-packages/torch/\u001b[0m\u001b[1;33mserialization.py\u001b[0m:\u001b[94m251\u001b[0m \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m in \u001b[92m__init__\u001b[0m                                                                                                     \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m                                                                                                                 \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m 250 \u001b[0m\u001b[2m│   \u001b[0m\u001b[94mdef\u001b[0m \u001b[92m__init__\u001b[0m(\u001b[96mself\u001b[0m, name, mode):                                                                      \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m \u001b[31m❱ \u001b[0m 251 \u001b[2m│   │   \u001b[0m\u001b[96msuper\u001b[0m(_open_file, \u001b[96mself\u001b[0m).\u001b[92m__init__\u001b[0m(\u001b[96mopen\u001b[0m(name, mode))                                               \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m 252 \u001b[0m                                                                                                         \u001b[31m│\u001b[0m\n",
       "\u001b[31m╰─────────────────────────────────────────────────────────────────────────────────────────────────────────────────╯\u001b[0m\n",
       "\u001b[1;91mFileNotFoundError: \u001b[0m\u001b[1m[\u001b[0mErrno \u001b[1;36m2\u001b[0m\u001b[1m]\u001b[0m No such file or directory: \u001b[32m'/data_fast/models/clip-base/checkpoints/ckpt_0/scaler.pt'\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# from capit.core.data.datasets import dataclass_collate\n",
    "# dataloader = torch.utils.data.DataLoader(dataset, batch_size=1, shuffle=False, collate_fn=dataclass_collate)\n",
    "# dummy_batch = next(iter(dataloader))\n",
    "dummy_dict_batch = {\n",
    "    key: (value.unsqueeze(0) if hasattr(value, \"unsqueeze\") else value)\n",
    "    for key, value in dataset[0].__dict__.items()\n",
    "}\n",
    "dummy_batch = dataset[0].__class__(**dummy_dict_batch)\n",
    "baseline = Ranker(\n",
    "    model_type=CLIPImageTextModel,\n",
    "    model_name_or_path=\"openai/clip-vit-base-patch32\",\n",
    "    repo_path=\"Antreas/baseline-100-100-27\",\n",
    "    model_name=\"ckpt_0\",\n",
    "    backbone_fine_tunable=True,\n",
    "    batch=dummy_batch,\n",
    "    cache_path=\"/data_fast/models/clip-base/\",\n",
    ")\n",
    "\n",
    "baseline_fine_tuned = Ranker(\n",
    "    model_type=CLIPImageTextModel,\n",
    "    model_name_or_path=\"openai/clip-vit-base-patch32\",\n",
    "    repo_path=\"Antreas/baseline-100-100-27\",\n",
    "    model_name=\"ckpt_95000\",\n",
    "    backbone_fine_tunable=True,\n",
    "    batch=dummy_batch,\n",
    "    cache_path=\"/data_fast/models/baseline-100-100-27/\",\n",
    ")\n",
    "\n",
    "cap = Ranker(\n",
    "    model_type=CAPCLIPImageTextModel,\n",
    "    model_name_or_path=\"openai/clip-vit-base-patch32\",\n",
    "    repo_path=\"Antreas/cap-100-100-24\",\n",
    "    model_name=\"ckpt_95000\",\n",
    "    backbone_fine_tunable=True,\n",
    "    batch=dummy_batch,\n",
    "    cache_path=\"/data_fast/models/cap-100-100-24/\",\n",
    ")\n",
    "\n",
    "model_dict = {\n",
    "    \"random\": RandomModel(),\n",
    "    \"clip-baseline\": baseline,\n",
    "    \"clip-fine-tuned\": baseline,\n",
    "    \"cap\": cap,\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import defaultdict\n",
    "from distutils.command.upload import upload\n",
    "from typing import Any\n",
    "import gradio as gr\n",
    "from PIL import Image\n",
    "\n",
    "\n",
    "def load_images(sample_idx):\n",
    "    sample = dataset[sample_idx]\n",
    "    collection_image_data = [\n",
    "        item[\"image\"] for item in sample.collection_paths\n",
    "    ]  # sample.collection_images\n",
    "    challenge_image_data = [\n",
    "        item[\"image\"] for item in sample.challenge_paths\n",
    "    ]  # sample.challenge_images\n",
    "\n",
    "    if collection_image_data is not None:\n",
    "        return *[gr.update(value=image) for image in collection_image_data], *[\n",
    "            gr.update(value=image) for image in challenge_image_data\n",
    "        ]\n",
    "    else:\n",
    "        return (*[gr.update(value=image) for image in challenge_image_data],)\n",
    "\n",
    "\n",
    "def build_demo(\n",
    "    model_dict: Any = None,\n",
    "    collection_num_images: int = 100,\n",
    "    challenge_num_images: int = 100,\n",
    "):\n",
    "    with gr.Blocks() as demo:\n",
    "        with gr.Row():\n",
    "            sample_idx_slider = gr.Slider(\n",
    "                maximum=len(dataset),\n",
    "                randomize=True,\n",
    "                step=1,\n",
    "                interactive=True,\n",
    "                label=\"Datapoint idx to sample\",\n",
    "                info=\"Select the idx to sample\",\n",
    "            )\n",
    "\n",
    "        with gr.Row():\n",
    "            with gr.Column(scale=1, min_width=224):\n",
    "                prompt = gr.Textbox(label=\"prompt\", value=\"\")\n",
    "            with gr.Column(scale=1, min_width=224):\n",
    "                rank_status = gr.Button(value=\"rank\", label=\"rank\")\n",
    "\n",
    "        with gr.Row():\n",
    "            if collection_num_images > 0:\n",
    "                collection_images = []\n",
    "                with gr.Column(scale=collection_num_images, min_width=224):\n",
    "                    for i in range(collection_num_images):\n",
    "                        collection_images.append(\n",
    "                            gr.Image(label=f\"collection-image-{i}\")\n",
    "                        )\n",
    "            with gr.Column(scale=challenge_num_images, min_width=224):\n",
    "                challenge_images = []\n",
    "                for i in range(challenge_num_images):\n",
    "                    challenge_images.append(\n",
    "                        gr.Image(label=f\"challenge-image-{i}\")\n",
    "                    )\n",
    "\n",
    "            ranked_images_dict = defaultdict(list)\n",
    "            for key, model in model_dict.items():\n",
    "                with gr.Column(scale=challenge_num_images, min_width=224):\n",
    "                    for i in range(challenge_num_images):\n",
    "                        ranked_images_dict[key].append(\n",
    "                            gr.Image(\n",
    "                                shape=(224, 224),\n",
    "                                label=f\"ranked-image-{key}-{i}\",\n",
    "                            )\n",
    "                        )\n",
    "\n",
    "        sample_idx_slider.change(\n",
    "            load_images,\n",
    "            inputs=[sample_idx_slider],\n",
    "            outputs=[*collection_images, *challenge_images],\n",
    "        )\n",
    "\n",
    "        for model_name, model in model_dict.items():\n",
    "            rank_status.click(\n",
    "                fn=model.rank,\n",
    "                inputs=[prompt, sample_idx_slider],\n",
    "                outputs=ranked_images_dict[model_name],\n",
    "            )\n",
    "\n",
    "    return demo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #800000; text-decoration-color: #800000\">╭─────────────────────────────────────── </span><span style=\"color: #800000; text-decoration-color: #800000; font-weight: bold\">Traceback </span><span style=\"color: #bf7f7f; text-decoration-color: #bf7f7f; font-weight: bold\">(most recent call last)</span><span style=\"color: #800000; text-decoration-color: #800000\"> ───────────────────────────────────────╮</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span> in <span style=\"color: #00ff00; text-decoration-color: #00ff00\">&lt;module&gt;</span>                                                                                                     <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>                                                                                                                 <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">2 │   │   │   │     </span>challenge_num_images=dataset.max_num_query_images_per_episode,                            <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span> <span style=\"color: #800000; text-decoration-color: #800000\">❱ </span>3 <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   │   │     </span>model_dict=model_dict)                                                                    <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">4 </span>demo.queue(concurrency_count=<span style=\"color: #0000ff; text-decoration-color: #0000ff\">8</span>)                                                                             <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">╰─────────────────────────────────────────────────────────────────────────────────────────────────────────────────╯</span>\n",
       "<span style=\"color: #ff0000; text-decoration-color: #ff0000; font-weight: bold\">NameError: </span>name <span style=\"color: #008000; text-decoration-color: #008000\">'model_dict'</span> is not defined\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[31m╭─\u001b[0m\u001b[31m──────────────────────────────────────\u001b[0m\u001b[31m \u001b[0m\u001b[1;31mTraceback \u001b[0m\u001b[1;2;31m(most recent call last)\u001b[0m\u001b[31m \u001b[0m\u001b[31m──────────────────────────────────────\u001b[0m\u001b[31m─╮\u001b[0m\n",
       "\u001b[31m│\u001b[0m in \u001b[92m<module>\u001b[0m                                                                                                     \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m                                                                                                                 \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m2 \u001b[0m\u001b[2m│   │   │   │     \u001b[0mchallenge_num_images=dataset.max_num_query_images_per_episode,                            \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m \u001b[31m❱ \u001b[0m3 \u001b[2m│   │   │   │     \u001b[0mmodel_dict=model_dict)                                                                    \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m4 \u001b[0mdemo.queue(concurrency_count=\u001b[94m8\u001b[0m)                                                                             \u001b[31m│\u001b[0m\n",
       "\u001b[31m╰─────────────────────────────────────────────────────────────────────────────────────────────────────────────────╯\u001b[0m\n",
       "\u001b[1;91mNameError: \u001b[0mname \u001b[32m'model_dict'\u001b[0m is not defined\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "demo = build_demo(\n",
    "    collection_num_images=dataset.max_num_collection_images_per_episode,\n",
    "    challenge_num_images=dataset.max_num_query_images_per_episode,\n",
    "    model_dict=model_dict,\n",
    ")\n",
    "demo.queue(concurrency_count=8)\n",
    "demo.launch(share=True, debug=True, enable_queue=True)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  },
  "vscode": {
   "interpreter": {
    "hash": "8be86470e38501aa34785446b144512d347203ba2fe09ff4115a3f561b2ac78b"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
